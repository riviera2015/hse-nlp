{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструменты для работы с языком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... или зачем нужна предобработка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('data/positive_tweets_russian.csv', \n",
    "                       sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('data/negative_tweets_russian.csv', \n",
    "                       sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, train_idx, test_idx = \\\n",
    "    train_test_split(df.text, df.label, range(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: CountVectorizer и TfidfVectorizer\n",
    "\n",
    "Объект CountVectorizer делает очень простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности n, где n -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 74591),\n",
       " ('petyachaykin', 68721),\n",
       " ('настроение', 164834),\n",
       " ('мне', 159438),\n",
       " ('подняла', 185548),\n",
       " ('shupova', 78073),\n",
       " ('люблю', 154791),\n",
       " ('тебя', 220946),\n",
       " ('не', 165676),\n",
       " ('могу', 159653)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.8 s, sys: 432 ms, total: 29.2 s\n",
      "Wall time: 4.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.76      0.76     28434\n",
      "   positive       0.76      0.77      0.77     28275\n",
      "\n",
      "avg / total       0.77      0.77      0.77     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.47      0.72      0.56     18243\n",
      "   positive       0.82      0.61      0.70     38466\n",
      "\n",
      "avg / total       0.71      0.65      0.66     56709\n",
      "\n",
      "CPU times: user 24.5 s, sys: 348 ms, total: 24.8 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer делает то же, что и CountVectorizer, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "tf (term frequency) – относительная частотность слова в документе:\n",
    "$$ tf(t,d) = \\frac{n_{t}}{\\sum_k n_{k}} $$\n",
    "\n",
    "idf (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ idf(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "Потом просто их перемножаем:\n",
    "$$tfidf_(t,d,D) = tf(t,d) \\times idf(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.73      0.76      0.75     26867\n",
      "   positive       0.78      0.75      0.77     29842\n",
      "\n",
      "avg / total       0.76      0.76      0.76     56709\n",
      "\n",
      "CPU times: user 13.5 s, sys: 224 ms, total: 13.7 s\n",
      "Wall time: 4.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз получилось хуже :( Вернёмся к CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "По дефолту векторизаторы используют свои *токенизаторы*, но можно это изменить, задав аргумент `tokenizer`.\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем. Поэтому лучше использовать готовые токенизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WordPunctTokenizer']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\", 'stop', 'me']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.80      0.76      0.78     29468\n",
      "   positive       0.76      0.80      0.78     27241\n",
      "\n",
      "avg / total       0.78      0.78      0.78     56709\n",
      "\n",
      "CPU times: user 50.1 s, sys: 268 ms, total: 50.4 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось чуть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте терепь лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 44s, sys: 26.6 s, total: 5min 11s\n",
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.74      0.76     29286\n",
      "   positive       0.74      0.77      0.75     27423\n",
      "\n",
      "avg / total       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'платили', 2368, 10),))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишите аналогичную функцию для лемматизации с pymorphy2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preproc_pymorphy(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = [pymorphy2_analyzer.parse(w)[0].normal_form for w in text.split()\n",
    "            if w not in stopwords.words('russian') + [' ', '\\n']]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Но не каждый хочет что-то исправлять:('"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['но', 'каждый', 'хотеть', 'чтоть', 'исправлять']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_preproc_pymorphy(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если использовать её в качестве препроцессора? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 16s, sys: 13.4 s, total: 5min 29s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc_pymorphy)\n",
    "bow = vec.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.74      0.76     29369\n",
      "   positive       0.73      0.77      0.75     27340\n",
      "\n",
      "avg / total       0.76      0.75      0.75     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) \n",
    "          if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69267),\n",
       " ('и', 54916),\n",
       " ('в', 52853),\n",
       " ('я', 52506),\n",
       " ('RT', 38070),\n",
       " ('на', 35715),\n",
       " ('http', 32992),\n",
       " ('что', 31472),\n",
       " ('...', 28773),\n",
       " ('с', 27176)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted = sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       1.00      1.00      1.00     27951\n",
      "   positive       1.00      1.00      1.00     28758\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56709\n",
      "\n",
      "CPU times: user 41 s, sys: 103 ms, total: 41.1 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_voc = {v: k for (k, v) in vec.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(',\n",
       " '|',\n",
       " 'о_о',\n",
       " 'o_o',\n",
       " '-/',\n",
       " 'cio_optimal',\n",
       " 'to_over_kill',\n",
       " 'do_or_die_xxx',\n",
       " 'prisonero_o',\n",
       " 'rt']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inv_voc[i] for i in np.argsort(clf.coef_)[:, :10].tolist()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[')', 'd', '*', 'dd', '^_^', 'ddd', '-d', '**', ':', 'dddd']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inv_voc[i] for i in np.argsort(clf.coef_)[:, -10:].tolist()[0][::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       1.00      0.85      0.92     32966\n",
      "   positive       0.83      1.00      0.90     23743\n",
      "\n",
      "avg / total       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.99      1.00      0.99     27861\n",
      "   positive       1.00      0.99      1.00     28848\n",
      "\n",
      "avg / total       0.99      0.99      0.99     56709\n",
      "\n",
      "CPU times: user 11 s, sys: 44.5 ms, total: 11 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Просто знайте, что так можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText\n",
    "\n",
    "https://fasttext.cc/docs/en/supervised-tutorial.html\n",
    "\n",
    "Если осталось время -- сами поизучайте этот модуль и попробуйти применить его к нашей задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import train_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_preprocess(df, out_file):\n",
    "    df['label'] = df['label'].apply(lambda l: '__label__' + str(l))\n",
    "    df[['label', 'text']].to_csv(out_file, index=None, header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yorko/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fasttext_preprocess(df.iloc[train_idx, :], 'data/tweets_russian_train.csv')\n",
    "fasttext_preprocess(df.iloc[test_idx, :], 'data/tweets_russian_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__negative \"аа да ну збс теперь  укольчики прописали пипец , болючие зараза(\"\r\n",
      "__label__positive \"фото) и тем кто лайкнет этот же вопрос:) — вот) http://t.co/4xKzMToHto\"\r\n",
      "__label__positive \"Капец...вспомнила как с девочками делали сникерс на технологии:D\"\r\n",
      "__label__positive \"@rutkovskaya_tan о боже,ты знаешь почти всё про меня:Dвсё самое не приличное ахаха\"\r\n",
      "__label__negative \"#вынеповерите #убейтеменя #какямог Я удалила #nyan #cat :С Заебало :(\"\r\n",
      "__label__negative \"А тем временем в США... не то, что у нас =( http://t.co/EhcdTnJTvO\"\r\n",
      "__label__negative \"У него слишком заметная внешность. =( #ff #follow\"\r\n",
      "__label__positive \"@Imichko @Svetonos блин им там не холодно целыми днями стоять то?))\"\r\n",
      "__label__negative \"@DeerofMirkwood я вот понимаю, что я ёлку хотела к 25 поставить, но не успею... столько по универу делать надо( прям печаль.\"\r\n",
      "__label__positive \"Зная себя, я бы постепенно просаживала их в макдаке - то есть платила бы за прыщи и кг)) Ничуть не лучше си\"\r\n"
     ]
    }
   ],
   "source": [
    "!head data/tweets_russian_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_supervised(\n",
    "        input='data/tweets_russian_train.csv', epoch=25, lr=1.0, wordNgrams=2, \n",
    "    verbose=2, minCount=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t56709\n",
      "P@1\t0.826\n",
      "R@1\t0.826\n"
     ]
    }
   ],
   "source": [
    "print_results(*model.test('data/tweets_russian_test.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
